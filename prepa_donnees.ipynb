{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728566cc-1454-4a6f-bb18-9881dfbefa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ea62c1-a381-4d8b-b2a2-ab5f999c5f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_output_25 = \"data/id_carr_1km_25m.tif\"\n",
    "RASTER_DEM_PATH = \"BDALTI/bdalti25m.tif\"\n",
    "RASTER_SLOPE_PATH = \"BDALTI/bdalti25m_slope_deg.tif\"\n",
    "TOTO = \"BDALTI/toto_slope_deg.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd673700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/id_carr_1km_25m.tif width :  126813\n",
      "BDALTI/bdalti25m.tif width :  47000\n",
      "BDALTI/bdalti25m_slope_deg.tif width :  47000\n"
     ]
    }
   ],
   "source": [
    "with rasterio.open(raster_output_25) as src_tile, \\\n",
    "         rasterio.open(RASTER_DEM_PATH) as src_dem, \\\n",
    "         rasterio.open(RASTER_SLOPE_PATH) as src_slope :\n",
    "    print(raster_output_25, \"width : \",src_tile.width)\n",
    "    print(RASTER_DEM_PATH, \"width : \",src_dem.width)\n",
    "    print(RASTER_SLOPE_PATH, \"width : \",src_slope.width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4ed3ca-2790-4c24-ab6b-1586cf25cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dad.columns =['pop21','code_a','code']\n",
    "dt.columns = ['pop21','code','code_a']\n",
    "\n",
    "dad_edges=dad.groupby(['code','code_a']).pop21.sum()\n",
    "dad_edges = dad_edges.reset_index()\n",
    "\n",
    "dt_edges=dt.groupby(['code','code_a']).pop21.sum()\n",
    "dt_edges = dt_edges.reset_index()\n",
    "\n",
    "dad_edges_final = dad_edges.loc[dad_edges['pop21']>50].copy()\n",
    "dt_edges_final = dt_edges.loc[dt_edges['pop21']>50].copy()\n",
    "\n",
    "pop = pop[['COM','PMUN']]\n",
    "pop.columns = ['code','pop']\n",
    "dad_edges_final = dad_edges_final.merge(pop, how='left', on='code')\n",
    "dad_edges_final['migra']=dad_edges_final.apply(lambda x: float(x['pop21'])/x['pop'], axis=1)\n",
    "dad_edges_final = dad_edges_final[['code','code_a','migra']]\n",
    "\n",
    "acti = acti[['CODGEO', 'P21_POP1564']]\n",
    "acti.columns = ['code','pop']\n",
    "dt_edges_final = dt_edges_final.merge(acti, how='left', on='code')\n",
    "dt_edges_final['d_t']=dt_edges_final.apply(lambda x: float(x['pop21'])/x['pop'], axis=1)\n",
    "dt_edges_final = dt_edges_final[['code','code_a','d_t']]\n",
    "\n",
    "dt_edges_final = dt_edges_final.loc[~dt_edges_final['code_a'].isin(['YYYYY', '99999'])].copy()\n",
    "dad_edges_final = dad_edges_final.loc[~dad_edges_final['code_a'].isin(['YYYYY', '99999'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e4c971-b790-4172-9d62-1178951f1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_final = dt_edges_final.merge(dad_edges_final, how='outer', on=['code','code_a']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf9de7b-87ce-44d8-9a66-1c34340cfeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_final.to_parquet('./data_GNN/edges.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3613e1-534a-4af1-add2-eea089efb2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = gpd.read_file(\"./data/bdtopo_routes.gpkg\", columns = ['ID','IMPORTANCE','geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7882c2e-2dcd-471f-abc9-3f2c09048bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def build_contact_opportunity_edges(gdf_communes):\n",
    "    \"\"\"\n",
    "    Construit le graphe d'adjacence physique pondéré par la longueur de la frontière commune.\n",
    "    \n",
    "    Args:\n",
    "        gdf_communes (GeoDataFrame): Doit contenir une colonne 'code' et 'geometry'.\n",
    "                                     Les polygones doivent être valides.\n",
    "    \n",
    "    Returns:\n",
    "        edge_index (LongTensor): [2, num_edges] Les connexions (Indices 0 à N)\n",
    "        edge_attr (FloatTensor): [num_edges, 1] La longueur normalisée (Log)\n",
    "        mapping_idx_code (dict): Pour retrouver le code commune à partir de l'index\n",
    "    \"\"\"\n",
    "    print(\"--- Construction du Graphe d'Opportunité de Contact (Physique) ---\")\n",
    "    \n",
    "    # 1. Préparation et Indexation\n",
    "    # On travaille sur une copie pour ne pas casser l'original\n",
    "    # On reset_index pour avoir des ID de nœuds propres (0, 1, 2... N) pour PyTorch\n",
    "    gdf = gdf_communes.reset_index(drop=True).copy()\n",
    "    \n",
    "    # On crée une colonne explicite pour l'index du nœud\n",
    "    gdf['node_idx'] = gdf.index\n",
    "    \n",
    "    # Création du mapping pour plus tard (Indispensable pour le niveau Macro)\n",
    "    # Ex: {0: '01001', 1: '01002'...}\n",
    "    mapping_idx_code = gdf['code'].to_dict()\n",
    "    \n",
    "    print(\"1. Nettoyage topologique léger...\")\n",
    "    # Buffer(0) ou très petit permet de réparer les géométries invalides \n",
    "    # et d'assurer que des polygones qui se touchent sont bien détectés\n",
    "    gdf['geometry'] = gdf.geometry.buffer(0.1) \n",
    "\n",
    "    print(\"2. Détection des voisins (Spatial Join Vectorisé)...\")\n",
    "    # On joint le dataframe avec lui-même pour trouver les intersections\n",
    "    # On garde les colonnes 'node_idx' pour savoir qui touche qui\n",
    "    # suffixe _left = Source, suffixe _right = Cible\n",
    "    adj = gpd.sjoin(\n",
    "        gdf[['geometry', 'node_idx']], \n",
    "        gdf[['geometry', 'node_idx']], \n",
    "        how='inner', \n",
    "        predicate='intersects' # 'intersects' est plus robuste que 'touches' pour les frontières\n",
    "    )\n",
    "    \n",
    "    # Filtre : On retire les auto-connexions (une commune se touche elle-même)\n",
    "    adj = adj[adj['node_idx_left'] != adj['node_idx_right']]\n",
    "    \n",
    "    print(f\"   -> {len(adj)} paires voisines potentielles détectées.\")\n",
    "    \n",
    "    print(\"3. Calcul précis des longueurs de frontières...\")\n",
    "    # Optimisation : Au lieu de faire une boucle, on aligne les géométries\n",
    "    # On récupère les géométries \"Gauche\" et \"Droite\" alignées sur les index du sjoin\n",
    "    geom_source = gdf.loc[adj['node_idx_left'], 'geometry'].values\n",
    "    geom_target = gdf.loc[adj['node_idx_right'], 'geometry'].values\n",
    "    \n",
    "    # Intersection vectorielle (GeoSeries vs GeoSeries)\n",
    "    # Cela génère des LineString (la frontière commune)\n",
    "    gs_source = gpd.GeoSeries(geom_source)\n",
    "    gs_target = gpd.GeoSeries(geom_target)\n",
    "    intersections = gs_source.intersection(gs_target)\n",
    "    \n",
    "    # Calcul de la longueur en mètres (si projection métrique type Lambert 93)\n",
    "    lengths = intersections.length\n",
    "    \n",
    "    # 4. Nettoyage final\n",
    "    # On ne garde que les frontières qui ont une longueur significative (> 1 mètre)\n",
    "    # Cela élimine les points de contact uniques ou les erreurs de topologie\n",
    "    mask_np = (lengths > 1.0).values \n",
    "    \n",
    "    final_src = adj['node_idx_left'].values[mask_np]\n",
    "    final_dst = adj['node_idx_right'].values[mask_np]\n",
    "    final_attr = lengths.values[mask_np]\n",
    "    \n",
    "    print(f\"   -> {len(final_src)} arêtes physiques validées (Longueur > 1m).\")\n",
    "\n",
    "    # 5. Conversion en Tenseurs PyTorch\n",
    "    # Format edge_index : [[Sources], [Cibles]]\n",
    "    edge_index = torch.tensor([final_src, final_dst], dtype=torch.long)\n",
    "    \n",
    "    # Format edge_attr : Normalisation Logarithmique\n",
    "    # Pourquoi ? Une frontière peut faire 10m ou 50km. \n",
    "    # Le réseau apprend mieux avec des valeurs compressées (ex: entre 0 et 10) qu'avec 50000.\n",
    "    # log1p calcule log(1 + x) pour gérer les petites valeurs proprement.\n",
    "    edge_attr = torch.tensor(final_attr, dtype=torch.float).log1p().unsqueeze(1)\n",
    "    \n",
    "    return edge_index, edge_attr, mapping_idx_code\n",
    "\n",
    "\n",
    "def add_road_crossings(edge_index, gdf_communes, gdf_routes):\n",
    "    \"\"\"\n",
    "    Calcule la perméabilité routière des frontières.\n",
    "    Utilise un index spatial pour la rapidité.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Préparation des données Routes ---\n",
    "    print(\"1. Préparation des routes et de l'index spatial...\")\n",
    "    \n",
    "    # On s'assure que l'index spatial existe (GeoPandas le crée à la volée sinon, mais c'est mieux d'être explicite)\n",
    "    # L'index permet de faire des requêtes spatiales instantanées\n",
    "    routes_sindex = gdf_routes.sindex \n",
    "    \n",
    "    # Feature Engineering : Pondération (si colonne NATURE existe)\n",
    "    # Adaptez les noms de colonnes selon votre version de la BD TOPO\n",
    "    if 'NATURE' in gdf_routes.columns:\n",
    "        poids_route = {\n",
    "            '1': 10.0,\n",
    "            '2': 8.0,\n",
    "            '3': 5.0,\n",
    "            '4': 3.0,\n",
    "            '5': 1.0,\n",
    "            '6': 0.0,\n",
    "        }\n",
    "        # On map et on remplit les inconnus par 1.0 (Route standard)\n",
    "        weights = gdf_routes['IMPORTANCE'].map(poids_route).fillna(1.0).values\n",
    "    else:\n",
    "        # Si pas de colonne NATURE, on compte juste le nombre de routes (poids 1)\n",
    "        weights = np.ones(len(gdf_routes))\n",
    "    \n",
    "    # On stocke les poids dans le dataframe pour y accéder facilement\n",
    "    gdf_routes['weight_calc'] = weights\n",
    "\n",
    "    # --- 2. Préparation des géométries Communes ---\n",
    "    # Pour accéder rapidement aux polygones par leur index numpy\n",
    "    geoms_communes = gdf_communes.geometry.values\n",
    "    \n",
    "    # On récupère les indices source/cible du graphe calculé précédemment\n",
    "    src_indices = edge_index[0].numpy()\n",
    "    dst_indices = edge_index[1].numpy()\n",
    "    \n",
    "    crossings_scores = []\n",
    "    \n",
    "    print(f\"2. Calcul des traversées pour {len(src_indices)} frontières...\")\n",
    "    \n",
    "    # --- 3. Boucle optimisée ---\n",
    "    for i, (s, d) in enumerate(zip(src_indices, dst_indices)):\n",
    "        \n",
    "        # A. Récupérer les deux polygones\n",
    "        poly_s = geoms_communes[s]\n",
    "        poly_d = geoms_communes[d]\n",
    "        \n",
    "        # B. Calculer la ligne frontière (Intersection)\n",
    "        # Note : intersection() peut renvoyer GeometryCollection ou MultiLineString\n",
    "        boundary = poly_s.intersection(poly_d)\n",
    "        \n",
    "        # Cas limites : Si l'intersection est vide ou juste un point\n",
    "        if boundary.is_empty or boundary.geom_type == 'Point' or boundary.length < 1.0:\n",
    "            crossings_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        # C. LE PRÉ-FILTRE (Spatial Index Query)\n",
    "        # C'est ici que la magie opère. Au lieu de tester toutes les routes,\n",
    "        # on demande à l'index : \"Donne-moi les ID des routes dont la boîte (bbox) touche la frontière\"\n",
    "        possible_matches_index = list(routes_sindex.query(boundary, predicate='intersects'))\n",
    "        \n",
    "        if not possible_matches_index:\n",
    "            crossings_scores.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        # D. Sélection des candidates\n",
    "        # On ne charge que les quelques routes candidates\n",
    "        candidate_roads = gdf_routes.iloc[possible_matches_index]\n",
    "        \n",
    "        # E. Intersection précise (Géométrique)\n",
    "        # On vérifie si ça coupe vraiment la ligne (et pas juste passer à côté dans la bbox)\n",
    "        real_intersections = candidate_roads[candidate_roads.intersects(boundary)]\n",
    "        \n",
    "        if real_intersections.empty:\n",
    "            crossings_scores.append(0.0)\n",
    "        else:\n",
    "            # F. Somme des poids\n",
    "            score = real_intersections['weight_calc'].sum()\n",
    "            crossings_scores.append(score)\n",
    "            \n",
    "        # Petit log pour suivre l'avancement (tous les 1000 couples)\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"   -> Traité {i}/{len(src_indices)} frontières...\")\n",
    "\n",
    "    return crossings_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49012439",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_communes = gpd.read_file(\"data/commune_francemetro_2023.gpkg\")\n",
    "gdf_routes = gpd.read_file('data/bdtopo_routes.gpkg', columns = ['ID', 'IMPORTANCE', 'geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc78f7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Construction du Graphe d'Opportunité de Contact (Physique) ---\n",
      "1. Nettoyage topologique léger...\n",
      "2. Détection des voisins (Spatial Join Vectorisé)...\n",
      "   -> 207748 paires voisines potentielles détectées.\n",
      "3. Calcul précis des longueurs de frontières...\n",
      "   -> 204284 arêtes physiques validées (Longueur > 1m).\n"
     ]
    }
   ],
   "source": [
    "# ÉTAPE 1 : Le Squelette Physique\n",
    "# On calcule qui se touche et la longueur de la frontière\n",
    "edge_index_phys, attr_longueur, mapping = build_contact_opportunity_edges(gdf_communes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87410c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Préparation des routes et de l'index spatial...\n",
      "2. Calcul des traversées pour 204284 frontières...\n",
      "   -> Traité 0/204284 frontières...\n",
      "   -> Traité 1000/204284 frontières...\n",
      "   -> Traité 2000/204284 frontières...\n",
      "   -> Traité 3000/204284 frontières...\n",
      "   -> Traité 4000/204284 frontières...\n",
      "   -> Traité 5000/204284 frontières...\n",
      "   -> Traité 6000/204284 frontières...\n",
      "   -> Traité 7000/204284 frontières...\n",
      "   -> Traité 8000/204284 frontières...\n",
      "   -> Traité 9000/204284 frontières...\n",
      "   -> Traité 10000/204284 frontières...\n",
      "   -> Traité 11000/204284 frontières...\n",
      "   -> Traité 12000/204284 frontières...\n",
      "   -> Traité 13000/204284 frontières...\n",
      "   -> Traité 14000/204284 frontières...\n",
      "   -> Traité 15000/204284 frontières...\n",
      "   -> Traité 16000/204284 frontières...\n",
      "   -> Traité 17000/204284 frontières...\n",
      "   -> Traité 18000/204284 frontières...\n",
      "   -> Traité 19000/204284 frontières...\n",
      "   -> Traité 20000/204284 frontières...\n",
      "   -> Traité 21000/204284 frontières...\n",
      "   -> Traité 22000/204284 frontières...\n",
      "   -> Traité 23000/204284 frontières...\n",
      "   -> Traité 24000/204284 frontières...\n",
      "   -> Traité 25000/204284 frontières...\n",
      "   -> Traité 26000/204284 frontières...\n",
      "   -> Traité 27000/204284 frontières...\n",
      "   -> Traité 29000/204284 frontières...\n",
      "   -> Traité 30000/204284 frontières...\n",
      "   -> Traité 31000/204284 frontières...\n",
      "   -> Traité 32000/204284 frontières...\n",
      "   -> Traité 33000/204284 frontières...\n",
      "   -> Traité 35000/204284 frontières...\n",
      "   -> Traité 36000/204284 frontières...\n",
      "   -> Traité 37000/204284 frontières...\n",
      "   -> Traité 38000/204284 frontières...\n",
      "   -> Traité 39000/204284 frontières...\n",
      "   -> Traité 40000/204284 frontières...\n",
      "   -> Traité 41000/204284 frontières...\n",
      "   -> Traité 42000/204284 frontières...\n",
      "   -> Traité 43000/204284 frontières...\n",
      "   -> Traité 44000/204284 frontières...\n",
      "   -> Traité 45000/204284 frontières...\n",
      "   -> Traité 46000/204284 frontières...\n",
      "   -> Traité 47000/204284 frontières...\n",
      "   -> Traité 48000/204284 frontières...\n",
      "   -> Traité 49000/204284 frontières...\n",
      "   -> Traité 50000/204284 frontières...\n",
      "   -> Traité 51000/204284 frontières...\n",
      "   -> Traité 52000/204284 frontières...\n",
      "   -> Traité 53000/204284 frontières...\n",
      "   -> Traité 54000/204284 frontières...\n",
      "   -> Traité 55000/204284 frontières...\n",
      "   -> Traité 56000/204284 frontières...\n",
      "   -> Traité 57000/204284 frontières...\n",
      "   -> Traité 58000/204284 frontières...\n",
      "   -> Traité 59000/204284 frontières...\n",
      "   -> Traité 60000/204284 frontières...\n",
      "   -> Traité 61000/204284 frontières...\n",
      "   -> Traité 62000/204284 frontières...\n",
      "   -> Traité 64000/204284 frontières...\n",
      "   -> Traité 65000/204284 frontières...\n",
      "   -> Traité 66000/204284 frontières...\n",
      "   -> Traité 67000/204284 frontières...\n",
      "   -> Traité 68000/204284 frontières...\n",
      "   -> Traité 69000/204284 frontières...\n",
      "   -> Traité 70000/204284 frontières...\n",
      "   -> Traité 71000/204284 frontières...\n",
      "   -> Traité 72000/204284 frontières...\n",
      "   -> Traité 73000/204284 frontières...\n",
      "   -> Traité 74000/204284 frontières...\n",
      "   -> Traité 75000/204284 frontières...\n",
      "   -> Traité 76000/204284 frontières...\n",
      "   -> Traité 77000/204284 frontières...\n",
      "   -> Traité 78000/204284 frontières...\n",
      "   -> Traité 79000/204284 frontières...\n",
      "   -> Traité 80000/204284 frontières...\n",
      "   -> Traité 81000/204284 frontières...\n",
      "   -> Traité 83000/204284 frontières...\n",
      "   -> Traité 84000/204284 frontières...\n",
      "   -> Traité 85000/204284 frontières...\n",
      "   -> Traité 86000/204284 frontières...\n",
      "   -> Traité 87000/204284 frontières...\n",
      "   -> Traité 88000/204284 frontières...\n",
      "   -> Traité 89000/204284 frontières...\n",
      "   -> Traité 90000/204284 frontières...\n",
      "   -> Traité 91000/204284 frontières...\n",
      "   -> Traité 92000/204284 frontières...\n",
      "   -> Traité 93000/204284 frontières...\n",
      "   -> Traité 94000/204284 frontières...\n",
      "   -> Traité 95000/204284 frontières...\n",
      "   -> Traité 96000/204284 frontières...\n",
      "   -> Traité 97000/204284 frontières...\n",
      "   -> Traité 98000/204284 frontières...\n",
      "   -> Traité 100000/204284 frontières...\n",
      "   -> Traité 101000/204284 frontières...\n",
      "   -> Traité 102000/204284 frontières...\n",
      "   -> Traité 103000/204284 frontières...\n",
      "   -> Traité 104000/204284 frontières...\n",
      "   -> Traité 105000/204284 frontières...\n",
      "   -> Traité 107000/204284 frontières...\n",
      "   -> Traité 108000/204284 frontières...\n",
      "   -> Traité 109000/204284 frontières...\n",
      "   -> Traité 110000/204284 frontières...\n",
      "   -> Traité 111000/204284 frontières...\n",
      "   -> Traité 112000/204284 frontières...\n",
      "   -> Traité 113000/204284 frontières...\n",
      "   -> Traité 114000/204284 frontières...\n",
      "   -> Traité 115000/204284 frontières...\n",
      "   -> Traité 116000/204284 frontières...\n",
      "   -> Traité 117000/204284 frontières...\n",
      "   -> Traité 118000/204284 frontières...\n",
      "   -> Traité 119000/204284 frontières...\n",
      "   -> Traité 122000/204284 frontières...\n",
      "   -> Traité 123000/204284 frontières...\n",
      "   -> Traité 124000/204284 frontières...\n",
      "   -> Traité 125000/204284 frontières...\n",
      "   -> Traité 126000/204284 frontières...\n",
      "   -> Traité 127000/204284 frontières...\n",
      "   -> Traité 128000/204284 frontières...\n",
      "   -> Traité 129000/204284 frontières...\n",
      "   -> Traité 130000/204284 frontières...\n",
      "   -> Traité 131000/204284 frontières...\n",
      "   -> Traité 132000/204284 frontières...\n",
      "   -> Traité 133000/204284 frontières...\n",
      "   -> Traité 134000/204284 frontières...\n",
      "   -> Traité 135000/204284 frontières...\n",
      "   -> Traité 136000/204284 frontières...\n",
      "   -> Traité 137000/204284 frontières...\n",
      "   -> Traité 138000/204284 frontières...\n",
      "   -> Traité 139000/204284 frontières...\n",
      "   -> Traité 140000/204284 frontières...\n",
      "   -> Traité 141000/204284 frontières...\n",
      "   -> Traité 142000/204284 frontières...\n",
      "   -> Traité 143000/204284 frontières...\n",
      "   -> Traité 144000/204284 frontières...\n",
      "   -> Traité 145000/204284 frontières...\n",
      "   -> Traité 146000/204284 frontières...\n",
      "   -> Traité 147000/204284 frontières...\n",
      "   -> Traité 148000/204284 frontières...\n",
      "   -> Traité 149000/204284 frontières...\n",
      "   -> Traité 150000/204284 frontières...\n",
      "   -> Traité 151000/204284 frontières...\n",
      "   -> Traité 152000/204284 frontières...\n",
      "   -> Traité 153000/204284 frontières...\n",
      "   -> Traité 154000/204284 frontières...\n",
      "   -> Traité 155000/204284 frontières...\n",
      "   -> Traité 156000/204284 frontières...\n",
      "   -> Traité 157000/204284 frontières...\n",
      "   -> Traité 158000/204284 frontières...\n",
      "   -> Traité 159000/204284 frontières...\n",
      "   -> Traité 160000/204284 frontières...\n",
      "   -> Traité 161000/204284 frontières...\n",
      "   -> Traité 162000/204284 frontières...\n",
      "   -> Traité 163000/204284 frontières...\n",
      "   -> Traité 164000/204284 frontières...\n",
      "   -> Traité 165000/204284 frontières...\n",
      "   -> Traité 166000/204284 frontières...\n",
      "   -> Traité 167000/204284 frontières...\n",
      "   -> Traité 168000/204284 frontières...\n",
      "   -> Traité 169000/204284 frontières...\n",
      "   -> Traité 170000/204284 frontières...\n",
      "   -> Traité 171000/204284 frontières...\n",
      "   -> Traité 172000/204284 frontières...\n",
      "   -> Traité 173000/204284 frontières...\n",
      "   -> Traité 174000/204284 frontières...\n",
      "   -> Traité 175000/204284 frontières...\n",
      "   -> Traité 176000/204284 frontières...\n",
      "   -> Traité 177000/204284 frontières...\n",
      "   -> Traité 178000/204284 frontières...\n",
      "   -> Traité 179000/204284 frontières...\n",
      "   -> Traité 180000/204284 frontières...\n",
      "   -> Traité 181000/204284 frontières...\n",
      "   -> Traité 182000/204284 frontières...\n",
      "   -> Traité 183000/204284 frontières...\n",
      "   -> Traité 184000/204284 frontières...\n",
      "   -> Traité 185000/204284 frontières...\n",
      "   -> Traité 186000/204284 frontières...\n",
      "   -> Traité 187000/204284 frontières...\n",
      "   -> Traité 188000/204284 frontières...\n",
      "   -> Traité 189000/204284 frontières...\n",
      "   -> Traité 190000/204284 frontières...\n",
      "   -> Traité 191000/204284 frontières...\n",
      "   -> Traité 192000/204284 frontières...\n",
      "   -> Traité 193000/204284 frontières...\n",
      "   -> Traité 194000/204284 frontières...\n",
      "   -> Traité 195000/204284 frontières...\n",
      "   -> Traité 196000/204284 frontières...\n",
      "   -> Traité 197000/204284 frontières...\n",
      "   -> Traité 198000/204284 frontières...\n",
      "   -> Traité 199000/204284 frontières...\n",
      "   -> Traité 201000/204284 frontières...\n",
      "   -> Traité 203000/204284 frontières...\n",
      "   -> Traité 204000/204284 frontières...\n"
     ]
    }
   ],
   "source": [
    "# ÉTAPE 2 : La Perméabilité\n",
    "# On réinjecte ce squelette (edge_index_phys) pour ne calculer les routes QUE sur les frontières existantes\n",
    "# (Sinon on calculerait des millions d'intersections inutiles)\n",
    "liste_poids_routes = add_road_crossings(edge_index_phys, gdf_communes, gdf_routes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd399e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÉTAPE 3 : La Fusion (Crucial !)\n",
    "# On transforme la liste des routes en Tenseur PyTorch\n",
    "attr_routes = torch.tensor(liste_poids_routes, dtype=torch.float).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb02618a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecteur d'arête physique prêt : torch.Size([204284, 2])\n"
     ]
    }
   ],
   "source": [
    "# On colle les deux attributs côte à côte pour faire le vecteur final de l'arête physique\n",
    "# Résultat : [Longueur, Nb_Routes] pour chaque arête\n",
    "final_edge_attr = torch.cat([attr_longueur, attr_routes], dim=1)\n",
    "\n",
    "print(\"Vecteur d'arête physique prêt :\", final_edge_attr.shape)\n",
    "# Doit afficher : [Nombre_Aretes, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1444c138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.7458, 26.0000],\n",
       "        [ 9.2431, 23.0000],\n",
       "        [ 8.6594, 12.0000],\n",
       "        ...,\n",
       "        [ 9.0923,  0.0000],\n",
       "        [ 8.4743,  2.0000],\n",
       "        [ 8.9491,  7.0000]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900f459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Nettoyage topologique léger...\n",
      "2. Détection des voisins (Spatial Join Vectorisé)...\n",
      "   -> 207748 paires voisines potentielles détectées.\n",
      "3. Calcul précis des longueurs de frontières...\n"
     ]
    }
   ],
   "source": [
    "gdf = gdf_communes.reset_index(drop=True).copy()\n",
    "    \n",
    "# On crée une colonne explicite pour l'index du nœud\n",
    "gdf['node_idx'] = gdf.index\n",
    "\n",
    "# Création du mapping pour plus tard (Indispensable pour le niveau Macro)\n",
    "# Ex: {0: '01001', 1: '01002'...}\n",
    "mapping_idx_code = gdf['code'].to_dict()\n",
    "\n",
    "print(\"1. Nettoyage topologique léger...\")\n",
    "# Buffer(0) ou très petit permet de réparer les géométries invalides \n",
    "# et d'assurer que des polygones qui se touchent sont bien détectés\n",
    "gdf['geometry'] = gdf.geometry.buffer(0.1) \n",
    "\n",
    "print(\"2. Détection des voisins (Spatial Join Vectorisé)...\")\n",
    "# On joint le dataframe avec lui-même pour trouver les intersections\n",
    "# On garde les colonnes 'node_idx' pour savoir qui touche qui\n",
    "# suffixe _left = Source, suffixe _right = Cible\n",
    "adj = gpd.sjoin(\n",
    "    gdf[['geometry', 'node_idx']], \n",
    "    gdf[['geometry', 'node_idx']], \n",
    "    how='inner', \n",
    "    predicate='intersects' # 'intersects' est plus robuste que 'touches' pour les frontières\n",
    ")\n",
    "\n",
    "# Filtre : On retire les auto-connexions (une commune se touche elle-même)\n",
    "adj = adj[adj['node_idx_left'] != adj['node_idx_right']]\n",
    "\n",
    "print(f\"   -> {len(adj)} paires voisines potentielles détectées.\")\n",
    "\n",
    "print(\"3. Calcul précis des longueurs de frontières...\")\n",
    "# Optimisation : Au lieu de faire une boucle, on aligne les géométries\n",
    "# On récupère les géométries \"Gauche\" et \"Droite\" alignées sur les index du sjoin\n",
    "geom_source = gdf.loc[adj['node_idx_left'], 'geometry'].values\n",
    "geom_target = gdf.loc[adj['node_idx_right'], 'geometry'].values\n",
    "\n",
    "# Intersection vectorielle (GeoSeries vs GeoSeries)\n",
    "# Cela génère des LineString (la frontière commune)\n",
    "gs_source = gpd.GeoSeries(geom_source)\n",
    "gs_target = gpd.GeoSeries(geom_target)\n",
    "intersections = gs_source.intersection(gs_target)\n",
    "\n",
    "# Calcul de la longueur en mètres (si projection métrique type Lambert 93)\n",
    "lengths = intersections.length\n",
    "\n",
    "# 4. Nettoyage final\n",
    "# On ne garde que les frontières qui ont une longueur significative (> 1 mètre)\n",
    "# Cela élimine les points de contact uniques ou les erreurs de topologie\n",
    "mask_np = (lengths > 1.0).values \n",
    "    \n",
    "# 2. On filtre les tableaux Numpy (positionnel strict)\n",
    "# On prend les .values D'ABORD, et on applique le masque ENSUITE\n",
    "final_src = adj['node_idx_left'].values[mask_np]\n",
    "final_dst = adj['node_idx_right'].values[mask_np]\n",
    "final_attr = lengths.values[mask_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b244473",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_np = (lengths > 1.0).values \n",
    "    \n",
    "# 2. On filtre les tableaux Numpy (positionnel strict)\n",
    "# On prend les .values D'ABORD, et on applique le masque ENSUITE\n",
    "final_src = adj['node_idx_left'].values[mask_np]\n",
    "final_dst = adj['node_idx_right'].values[mask_np]\n",
    "final_attr = lengths.values[mask_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9af44932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check tailles : Src=204284, Attr=204284\n"
     ]
    }
   ],
   "source": [
    "print(f\"Check tailles : Src={len(final_src)}, Attr={len(final_attr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66beb9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00045300e+00, 1.00045300e+00, 1.00110600e+00, ...,\n",
       "       7.61221020e+04, 8.76085924e+04, 8.76085924e+04], shape=(204284,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_attr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
